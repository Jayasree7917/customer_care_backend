# ğŸ¤– Customer Care Backend

A Django REST API backend for an AI-powered chatbot that supports multiple models:
- **Google Gemini**
- **OpenRouter**
- **Groq**
- **Ollama (local models)**

The project uses **Django REST Framework (DRF)** to expose an endpoint `/chat/` where you can send user messages and get AI responses.

---

## ğŸš€ Features
- REST API for chatting with multiple AI models
- Supports **Gemini, OpenRouter, Groq, Ollama**
- Stores chat history in a database
- Modular and extensible design
- `.env` based API key configuration

---

## ğŸ“‚ Project Structure
```

â”œâ”€â”€ chatbot_app/             # Django app
â”‚   â”œâ”€â”€ models.py            # ChatMessage model
â”‚   â”œâ”€â”€ views.py             # API logic
â”‚   â”œâ”€â”€ urls.py              # Routes for API
â”œâ”€â”€ requirements.txt         # Dependencies
â”œâ”€â”€ manage.py                # Django management script
â””â”€â”€ README.md                # Documentation

````

---

## âš¡ Setup & Installation

### 1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/your-username/django-ai-chatbot.git
cd django-ai-chatbot
````

### 2ï¸âƒ£ Create & activate a virtual environment

```bash
python -m venv venv
source venv/bin/activate   # On macOS/Linux
venv\Scripts\activate      # On Windows
```

### 3ï¸âƒ£ Install dependencies

```bash
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configure environment variables

Create a `.env` file in the project root and add:

```ini
# Gemini
GEMINI_API_KEY=your_gemini_api_key

# OpenRouter
OPENROUTER_API_KEY=your_openrouter_api_key
OPENROUTER_MODEL=openrouter/model-name

# Groq
GROQ_API_KEY=your_groq_api_key
GROQ_MODEL=groq/model-name

# Ollama (local)
OLLAMA_MODEL=llama2
```

### 5ï¸âƒ£ Run migrations

```bash
python manage.py migrate
```

### 6ï¸âƒ£ Start the server

```bash
python manage.py runserver
```

---

## ğŸ”‘ API Endpoints

### ğŸ  Root

```http
GET /
```

Returns a welcome message.

### ğŸ’¬ Chat

```http
POST /chat/
Content-Type: application/json

{
  "message": "Hello AI!",
  "model": "gemini"   # options: gemini | openrouter | groq | ollama
}
```

#### âœ… Example Response

```json
{
  "reply": "Hello! How can I assist you today?"
}
```

---

## ğŸ—„ Database

All chat messages are stored in the `ChatMessage` model with:

* `sender` (user/ai)
* `message`
* `timestamp`

---

## ğŸ›  Tech Stack

* **Python 3.10+**
* **Django 5+**
* **Django REST Framework**
* **Google Generative AI (Gemini)**
* **OpenRouter**
* **Groq SDK**
* **Ollama (for local models)**

---

## ğŸ“œ License

This project is licensed under the **MIT License**.

---

âœ¨ Built with Django & DRF for AI-powered chat

